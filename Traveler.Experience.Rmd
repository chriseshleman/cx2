---
title: "Traveler Experience"
author: "Planning and Regional Development"
date: "11/13/2019"
output: pdf_document
---

```{r setup, echo=FALSE, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, include=FALSE)
```

\pagenumbering{arabic} 

#JD Power data 

The folders include two critical raw data files: 

1. One ASQ raw data file from 2019 (ACI ASQ Survey Main_ Q3 2019 Data-EXCEL-v1.xlsx), and,
2. One JD Power raw data file from 2018 (Client_SPSS_File_W1W4 (1).csv). 

Everything else is a PDF report or, in a couple of cases, Excel files that include synthesized tables or data dictionaries. That's as of the morning of 11/5. 

We started with those two data files. In particular, we were interested in the JD Power data since it's potentially so rich and provides a new data source outside of ASQ. 

```{r}
setwd("~/Dropbox/Work and research/Port Authority/cx2") 
library(readxl) 
library(mice) 
library(dplyr) 
library(Hmisc) 
library(imputeMissings) 
library(ggplot2) 
library(beepr) 
library(ggdendro) 
library(reshape2) 
library(tidyr) 
library(remotes) 
#remotes::install_github("njtierney/naniar") 
library(naniar) 
library(tidyverse) 
library(tree) 
library(rpart) 

rm(list = ls()) # clear global environment 
cat("\014") # clear the console 
options(warn=-1) # suppress annoying warnings 
```

The ASQ data is relatively clean. The JD Power data set is rough, but potentially very rich. It has more than 400 fields and around 40,000 observations taken from four survey visits (multiple days each) in late 2017 through fall 2018. The data "labels" are stored in a separate file with different formatting so we've transposed them and glued them onto the master data set. 

```{r}
jd18 = read.csv("./JD Power/2018 Study/Raw Data/Client_SPSS_File_W1W4 (1).csv")
jdnames = read_excel("./JD Power/2018 Study/Raw Data/2018 W1-W4 Data Dictionary.xlsx", skip = 1) 
jdnames = as.data.frame(jdnames) 
```

```{r, include=TRUE}
#table(jd18$SURVEY_MONTH, jd18$SURVEY_YEAR) 
```

```{r, echo=FALSE, include=FALSE}
head(jdnames$Variable, 20) 
head(names(jd18),20) 
tail(jdnames$Variable, 20) 
tail(names(jd18),20) 
```


```{r}
jdnames = head(jdnames,411) # Only the first 411 rows count 
jdnames = jdnames[,c(1,3)] # Pick only field names and label. Label will be important later.
jdnames$Label = gsub(" ",".",jdnames$Label) # Remove spaces in names, transpose them, and take the labels only for short-term use.
```

```{r}
#jdnames = as.data.frame(t(jdnames)) 
#jdnames = jdnames %>% 
#  head() %>% 
#  janitor::row_to_names(1) 
#jd18.test = rbind(jdnames,jd18) 

#jdnames.t = as.data.frame(gsub("[[:punct:]]", "", as.matrix(jdnames.t))) # Remove special characters.

#jd18.test = jd18.test %>% 
#  head() %>% 
#  janitor::row_to_names(1) # Nope

# rm(jd182) 
```


```{r}
jdnome = c(t(jdnames$Label))
names(jd18) = jdnome 
```

"Overall.Satisfaction.Index" is likely the variable of most interest. It appears to be scaled from, roughly, 100-1000, which seems to match some of the visualizations in the PDF reports:

```{r, echo=FALSE, include=TRUE}
summary(jd18$Overall.Satisfaction.Index)
```

```{r}
# Take a hint from https://uc-r.github.io/hc_clustering 
jd18.2 = jd18[,-(1:7)] 
#jd18.2.2 = jd18.2[,101:200] 
#jd18.2.3 = jd18.2[201:300]
#jd18.2.4 = jd18.2[301:398]
#str(jd18.2.2) 
#str(jd18.2.3) 
#str(jd18.2.4) 
jd18.2$Departure.flight..Travel.Dates = NULL 
jd18.2$Arrival.flight..Travel.Dates = NULL 
jd18.2$ZipPostal.code = NULL 
jd18.2$MRPSURVEYDPSTACKID = NULL 
jd18.2$AF7.Verbatim = NULL 
jd18.2$Why.public.transportation.not.used = NULL 
jd18.2$What.foodBeverages.want.to.find = NULL 
jd18.2$F15.Verbatim = NULL 
jd18.2$RS6.Verbatim = NULL 
jd18.2$TF2B.Verbatim = NULL 
jd18.2$YF2.Verbatim = NULL 
jd18.2$YF2.Verbatim.1 = NULL 
jd18.2$L7.Verbatim = NULL 
jd18.2$Reason.for.NPS.rating = NULL 
jd18.2$Other.9 = NULL 
jd18.2$FB2.Verbatim = NULL 
jd18.2$RS196.Verbatim = NULL 
jd18.2$RS197.Verbatim = NULL 
jd18.2$Regarding.the.cleanliness.of.the.terminal.why.did.you.provide.a.rating.of.MRKTF21B.for.MRKAIRPORT = NULL 

not_all_na = function(x) {!all(is.na(x))} # Quick function 
jd18.2 = jd18.2 %>% select_if(not_all_na) # Remove variables with all NAs. 
```

##Missing data

The JD Power data is big, so we started with a sample, described below. Notice the number of missing observations (NAs) and the variation in those missing observations' propensity across different variables. And, to make matters tougher, the missing observations' are distributed variously across survey respondents - they're not limited to certain questions. So when you try and just drop respondents with any missing responses or, conversely, drop survey questions with any NA responses, you're left with next-to-no data. 

```{r, echo=TRUE}
pmiss = function(x){sum(is.na(x))/length(x)*100} 
# Taking a tip here from https://www.r-bloggers.com/imputing-missing-data-with-r-mice-package/ 
```

We started with a random-ish sample: 12% of the variables (we just picked every 8th column) and took a truly random sample of 4,000 observations, which is around 10% of the full list of respondents. 

```{r}
jd18.2.small = jd18.2[, seq(1, ncol(jd18.2), 8)]
jd18.2.small = jd18.2.small[sample(nrow(jd18.2.small), 4000), ] # 4000 random rows 
```

There are obvious patterns in that sample: 

```{r, include=TRUE, fig.width=8, fig.height=10}
gg_miss_var(jd18.2.small, show_pct=TRUE)
#Kudos to Nick Tierney for the tips: https://cran.r-project.org/web/packages/naniar/vignettes/naniar-visualisation.html.
```

```{r, echo=TRUE, include=FALSE}
head(apply(jd18.2.small,2,pmiss),15)
```

Overall, roughly half of the data is missing. And it definitely isn't missing at random. Some variables are missing no observation. Many are missing around 20 percent - and that number looks very consistant across that group of variables. Then the share of missing observations increases. This continues all the way up until a collection of variables show no actual measurements - all observations there are missing. 

```{r, include=TRUE, fig.width=8, fig.height=10}
vis_miss(jd18.2.small)
```

So we can evaluate NAs further or we can limit the data set to everything missing no more than that much data, then do some strategic selection or imputation and move forward. 

A few potential next steps, in order: 

1. Identify variables with no (or practically no) missing observations and review the list. 
2. Repeat, but including variables up to the 21 percent missing observation shelf. 
3. Consider using subset #1 or #2 for some predictive work. 
4. Perform #3 again but using ASQ data. 
5. Compare top predictors across each data set. Anything interesting or surprising? 

We've taken step 1 below. 

###1. Variables (JD Power) with no NAs. 
```{r}
share.Na = as.data.frame(t(jd18.2 %>% 
   summarise_each(funs(100*mean(is.na(.)))))) 
```

There are 40 variables without missing values: 
```{r, include=TRUE, echo=FALSE} 
short = subset(share.Na, share.Na==0) 
names(short) = c("Share.NA") 
short 
short = jd18.2[ , colSums(is.na(jd18.2)) == 0] 

```

.
Another eight have around 13 or 14 percent missing values: 
```{r, include=TRUE, echo=FALSE}
short2 = subset(share.Na, share.Na>0 & share.Na<15) #21
names(short2) = c("Share.NA") 
short2
rm(short2) 
```

.
Then 140 variables missing exactly 21.636 percent of their observations! Here they are: 
```{r, include=TRUE, echo=FALSE}
short3 = subset(share.Na, share.Na>21.63601 & share.Na<21.6361) 
names(short3) = c("Share.NA") 
short3 
rm(short3) 
```


\pagebreak

##Summary stats for JD Power variables with no missing observations
```{r, include=TRUE}
#means = as.data.frame(colMeans(is.na(jd18.2))) 
jd18.2nona = jd18.2[ , colSums(is.na(jd18.2)) == 0] 
summary(jd18.2nona)
write.csv(jd18.2nona,"./JDPower18_noNA.csv") 
```

\pagebreak

##Same thing for ASQ data (all of it - only 11 variables there have no missing values)
```{r, include=TRUE}
asq193 = read_excel("./ACI - ASQ/2019 Q3/ACI ASQ Survey Main_ Q3 2019 Data-EXCEL-v1.xlsx")
asq193 = as.data.frame(asq193) 
names(asq193) = tolower(names(asq193)) 
summary(asq193)
```


\pagebreak

#PAGE LEFT INTENTIONALLY BLANK

\pagebreak

#APPENDIX

##Full variable list (labels):

```{r, echo=FALSE, include=TRUE}
names(jd18.2) 
```

##Summaries of each: 
```{r, echo=FALSE, include=TRUE}
summary(jd18.2) 
```

```{r}
options(warn=0) # turn annoying warnings back on
```
